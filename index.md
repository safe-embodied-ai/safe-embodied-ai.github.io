---
layout: about
title: Home
---

# Safe Embodied AI: Theory & Practice for Deployability in the Field Workshop @ RSS 2025
---
### **> Date:** TBD
### **> Place:** University of Southern California, Los Angeles, California
---

## Introduction
Despite recent breakthroughs in embodied AI, ensuring the safety, robustness, and deployability of these systems in high-risk settings, such as field robotics, remains a critical challenge. This workshop will focus on safety considerations in unstructured, outdoor, industrial, and high-stakes environments—characterized by uncertainty, open-world dynamics, and extreme conditions. Developing safe robotic methods requires interdisciplinary collaboration across diverse sub-communities, including field robotics, AI safety, robot foundation models, control theory, and formal verification. This workshop aims to serve as a platform for fostering such collaboration, advancing both the theoretical foundations and practical applications of safe embodied AI in real-world field deployments. Bringing together researchers, practitioners, and industry leaders, this workshop aims to foster dialogue between academia and industry, bridging the gap between theoretical advancements and practical deployment. 

Key topics include:
**Safe Learning-Based Control and Planning:**
* What are the challenges of integrating safety into learning-based systems?
* How can we develop certifiable learning machines that enable robots to discover new behaviors while guaranteeing safety, reliability, and efficiency?
* How to balance the trade-offs between performance and safety to avoid learning overly conservative behavior?

**Safety Guarantees:**
* How can formal verification be applied to learning-based methods?
* What methods can provide statistical safety guarantees in field robotics?
* What role can hybrid approaches—blending traditional methods and learning methods—play in ensuring safety in robotics?

**Risk and Uncertainty:**
* What are efficient and theoretically grounded methods for computing aleatory and/or epistemic uncertainty in deep learning models?
* How can risk quantification enhance safety in learning-based control?
* What are effective strategies for risk- and uncertainty-aware decision-making?

**Foundation Models in Robotics:**
* How can LLMs/VLMs/VLAs enhance robotic safety through contextual understanding and reasoning?
* How can we address hallucinations in foundation models and ensure they do not lead to safety issues?
* How can we balance performance, latency, and resource constraints when deploying foundation models on the edge?

**Validation, Simulation, and Safety Benchmarks:**
* How can we create high-fidelity, physics-based simulation environments and digital twins to evaluate robotic safety?
* How can we develop realistic benchmarks, datasets, and standardized metrics for measuring safety in field, industrial, and outdoor robotics?
* How to define good safety specifications when dealing with image-based inputs?

## Invited Speakers
<div class="row projects pt-1 pb-1">
    <div class="col-sm-4">
      {% include people.html name="Dorsa Sadigh" affiliation="Stanford University" url="https://dorsa.fyi/" img="assets/img/speakers/dorsa.jpeg"%}
    </div>
    <div class="col-sm-4">
      {% include people.html name="Ali Agha" affiliation="Field AI" url="https://scholar.google.com/citations?user=36qnUD4AAAAJ&hl=en" img="assets/img/speakers/ali.jpeg"%}
    </div>
    <div class="col-sm-4">
      {% include people.html name="Vijay Janapa Reddi" affiliation="Harvard University" url="https://edge.seas.harvard.edu/" img="assets/img/speakers/vijay.jpeg"%}
    </div>
    <div class="col-sm-4">
      {% include people.html name="Roozbeh Mottaghi" affiliation="FAIR, University of Washington" url="https://roozbehm.info/" img="assets/img/speakers/roozbeh.jpg"%}
    </div>
    <div class="col-sm-4">
      {% include people.html name="Kimin Lee" affiliation="KAIST" url="https://sites.google.com/view/kiminlee" img="assets/img/speakers/kimin.png"%}
    </div>
    <div class="col-sm-4">
      {% include people.html name="Michael Ryoo" affiliation="Salesforce AI Research, Stony Brook University" url="http://michaelryoo.com/" img="assets/img/speakers/michael.jpeg"%}
    </div>
    <div class="col-sm-4">
      {% include people.html name="Ding Zhao" affiliation="Carnegie Mellon University" url="https://safeai-lab.github.io/" img="assets/img/speakers/ding.jpeg"%}
    </div>
    <div class="col-sm-4">
      {% include people.html name="Michael Everett" affiliation="Northeastern University" url="https://mfe7.github.io/" img="assets/img/speakers/michael.jpg"%}
    </div>
    <div class="col-sm-4">
      {% include people.html name="Anushri Dixit" affiliation="University of California, Los Angeles" url="https://www.anushridixit.com/" img="assets/img/speakers/anushri.jpeg"%}
    </div>
    <div class="col-sm-4">
      {% include people.html name="Sydney M. Katz" affiliation="Stanford University" url="https://sydneymkatz.com/" img="assets/img/speakers/sydney.jpg"%}
    </div>

</div>

## Organizers
<div class="row row-cols-2 projects pt-3 pb-3">
  {% include people_horizontal.html name="Dong-Ki Kim" affiliation="Field AI" url="https://scholar.google.com/citations?user=Yl_3akYAAAAJ&hl=en" img="assets/img/organizers/dongki.jpeg" %}
  {% include people_horizontal.html name="Shayegan Omidshafiei" affiliation="Field AI" url="https://scholar.google.com/citations?user=nm5wMNUAAAAJ&hl=en" img="assets/img/organizers/shayegan.jpeg" %}
  {% include people_horizontal.html name="Muhammad Fadhil Ginting" affiliation="Stanford University" url="https://scholar.google.com/citations?user=RTycc8AAAAAJ&hl=en" img="assets/img/organizers/fadhil.jpeg" %}
  {% include people_horizontal.html name="Mansur M. Arief" affiliation="Stanford University" url="https://mansurarief.github.io/" img="assets/img/organizers/mansur.jpg" %}
  {% include people_horizontal.html name="Mykel J. Kochenderfer" affiliation="Stanford University" url="https://mykel.kochenderfer.com/" img="assets/img/organizers/mykel.jpeg" %}
  {% include people_horizontal.html name="Jason Jabbour" affiliation="Harvard University" url="https://jabbourjason.com/" img="assets/img/organizers/jason.jpg" %}
  </div>

## Contact
If you have any questions, please contact us at [safe-embodied-ai-workshop@googlegroups.com](mailto:safe-generative-ai-workshop@googlegroups.com).
